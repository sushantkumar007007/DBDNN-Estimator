{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load rbm.py\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection\n",
    "import pandas as pd\n",
    "\n",
    "class RBM:\n",
    "  \n",
    "  def __init__(self, num_visible, num_hidden):\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_visible = num_visible\n",
    "    self.debug_print = True\n",
    "\n",
    "    # Initialize a weight matrix, of dimensions (num_visible x num_hidden), using\n",
    "    # a uniform distribution between -sqrt(6. / (num_hidden + num_visible))\n",
    "    # and sqrt(6. / (num_hidden + num_visible)). One could vary the \n",
    "    # standard deviation by multiplying the interval with appropriate value.\n",
    "    # Here we initialize the weights with mean 0 and standard deviation 0.1. \n",
    "    # Reference: Understanding the difficulty of training deep feedforward \n",
    "    # neural networks by Xavier Glorot and Yoshua Bengio\n",
    "    np_rng = np.random.RandomState(1234)\n",
    "\n",
    "    self.weights = np.asarray(np_rng.uniform(\n",
    "\t\t\tlow=-0.1 * np.sqrt(6. / (num_hidden + num_visible)),\n",
    "                       \thigh=0.1 * np.sqrt(6. / (num_hidden + num_visible)),\n",
    "                       \tsize=(num_visible, num_hidden)))\n",
    "\n",
    "\n",
    "    # Insert weights for the bias units into the first row and first column.\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 0)\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 1)\n",
    "\n",
    "  def train(self, data, max_epochs = 1000, learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Train the machine.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row is a training example consisting of the states of visible units.    \n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Insert bias units of 1 into the first column.\n",
    "    #data = np.insert(data, 0, 1, axis = 1)\n",
    "    data = pd.read_csv('cross mega.csv')\n",
    "    data = pd.read_csv('cross mega.csv')\n",
    "    X = data.drop(['bug'], axis = 1)\n",
    "    X = np.array(X)\n",
    "    Y = data['bug']\n",
    "    X_new = np.squeeze(np.asarray(X))\n",
    "    Y_new = np.squeeze(np.asarray(Y))\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(X_new,Y_new,test_size = 0.2, random_state = 0)\n",
    "    train_x = np.reshape(train_x, (train_x.shape[0], 1, train_x.shape[1]))\n",
    "    test_x = np.reshape(test_x, (test_x.shape[0], 1, test_x.shape[1]))\n",
    "\n",
    "    for epoch in range(max_epochs):      \n",
    "      # Clamp to the data and sample from the hidden units. \n",
    "      # (This is the \"positive CD phase\", aka the reality phase.)\n",
    "      pos_hidden_activations = np.dot(data, self.weights)      \n",
    "      pos_hidden_probs = self._logistic(pos_hidden_activations)\n",
    "      pos_hidden_probs[:,0] = 1 # Fix the bias unit.\n",
    "      pos_hidden_states = pos_hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "      # Note that we're using the activation *probabilities* of the hidden states, not the hidden states       \n",
    "      # themselves, when computing associations. We could also use the states; see section 3 of Hinton's \n",
    "      # \"A Practical Guide to Training Restricted Boltzmann Machines\" for more.\n",
    "      pos_associations = np.dot(data.T, pos_hidden_probs)\n",
    "\n",
    "      # Reconstruct the visible units and sample again from the hidden units.\n",
    "      # (This is the \"negative CD phase\", aka the daydreaming phase.)\n",
    "      neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)\n",
    "      neg_visible_probs = self._logistic(neg_visible_activations)\n",
    "      neg_visible_probs[:,0] = 1 # Fix the bias unit.\n",
    "      neg_hidden_activations = np.dot(neg_visible_probs, self.weights)\n",
    "      neg_hidden_probs = self._logistic(neg_hidden_activations)\n",
    "      # Note, again, that we're using the activation *probabilities* when computing associations, not the states \n",
    "      # themselves.\n",
    "      neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)\n",
    "\n",
    "      # Update weights.\n",
    "      self.weights += learning_rate * ((pos_associations - neg_associations) / num_examples)\n",
    "\n",
    "      error = np.sum((data - neg_visible_probs) ** 2)\n",
    "      if self.debug_print:\n",
    "        print(\"Epoch %s: error is %s\" % (epoch, error))\n",
    "\n",
    "  def run_visible(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of visible units, to get a sample of the hidden units.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the visible units.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hidden_states: A matrix where each row consists of the hidden units activated from the visible\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "    \n",
    "    #num_examples = data.shape[0]\n",
    "    \n",
    "    # Create a matrix, where each row is to be the hidden units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "    \n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    #data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the hidden units.\n",
    "    hidden_activations = np.dot(data, self.weights)\n",
    "    # Calculate the probabilities of turning the hidden units on.\n",
    "    hidden_probs = self._logistic(hidden_activations)\n",
    "    # Turn the hidden units on with their specified probabilities.\n",
    "    hidden_states[:,:] = hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # hidden_states[:,0] = 1\n",
    "  \n",
    "    # Ignore the bias units.\n",
    "    hidden_states = hidden_states[:,1:]\n",
    "    return hidden_states\n",
    "    \n",
    "  # TODO: Remove the code duplication between this method and `run_visible`?\n",
    "  def run_hidden(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of hidden units, to get a sample of the visible units.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the hidden units.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    visible_states: A matrix where each row consists of the visible units activated from the hidden\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Create a matrix, where each row is to be the visible units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "\n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the visible units.\n",
    "    visible_activations = np.dot(data, self.weights.T)\n",
    "    # Calculate the probabilities of turning the visible units on.\n",
    "    visible_probs = self._logistic(visible_activations)\n",
    "    # Turn the visible units on with their specified probabilities.\n",
    "    visible_states[:,:] = visible_probs > np.random.rand(num_examples, self.num_visible + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # visible_states[:,0] = 1\n",
    "\n",
    "    # Ignore the bias units.\n",
    "    visible_states = visible_states[:,1:]\n",
    "    return visible_states\n",
    "    \n",
    "  def daydream(self, num_samples):\n",
    "    \"\"\"\n",
    "    Randomly initialize the visible units once, and start running alternating Gibbs sampling steps\n",
    "    (where each step consists of updating all the hidden units, and then updating all of the visible units),\n",
    "    taking a sample of the visible units at each step.\n",
    "    Note that we only initialize the network *once*, so these samples are correlated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    samples: A matrix, where each row is a sample of the visible units produced while the network was\n",
    "    daydreaming.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a matrix, where each row is to be a sample of of the visible units \n",
    "    # (with an extra bias unit), initialized to all ones.\n",
    "    samples = np.ones((num_samples, self.num_visible + 1))\n",
    "\n",
    "    # Take the first sample from a uniform distribution.\n",
    "    samples[0,1:] = np.random.rand(self.num_visible)\n",
    "\n",
    "    # Start the alternating Gibbs sampling.\n",
    "    # Note that we keep the hidden units binary states, but leave the\n",
    "    # visible units as real probabilities. See section 3 of Hinton's\n",
    "    # \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "    # for more on why.\n",
    "    for i in range(1, num_samples):\n",
    "      visible = samples[i-1,:]\n",
    "\n",
    "      # Calculate the activations of the hidden units.\n",
    "      hidden_activations = np.dot(visible, self.weights)      \n",
    "      # Calculate the probabilities of turning the hidden units on.\n",
    "      hidden_probs = self._logistic(hidden_activations)\n",
    "      # Turn the hidden units on with their specified probabilities.\n",
    "      hidden_states = hidden_probs > np.random.rand(self.num_hidden + 1)\n",
    "      # Always fix the bias unit to 1.\n",
    "      hidden_states[0] = 1\n",
    "\n",
    "      # Recalculate the probabilities that the visible units are on.\n",
    "      visible_activations = np.dot(hidden_states, self.weights.T)\n",
    "      visible_probs = self._logistic(visible_activations)\n",
    "      visible_states = visible_probs > np.random.rand(self.num_visible + 1)\n",
    "      samples[i,:] = visible_states\n",
    "\n",
    "    # Ignore the bias units (the first column), since they're always set to 1.\n",
    "    return samples[:,1:]        \n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-33ace6a0ef31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRBM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_visible\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m    \u001b[1;31m# np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "def _logistic(self, x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  r = RBM(num_visible = 6, num_hidden = 2)\n",
    "  training_data = np.array(X_new)\n",
    "   # np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])\n",
    "  r.train(training_data, max_epochs = 5000)\n",
    "  print(r.weights)\n",
    "  #user = np.array([[0,0,0,1,1,0]])\n",
    "  print(r.run_visible(user))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -26.00, time = 0.53s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -25.68, time = 0.15s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -25.18, time = 0.09s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -23.14, time = 0.10s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.82, time = 0.12s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.74, time = 0.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -21.47, time = 0.10s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -21.10, time = 0.06s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.80, time = 0.09s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.55, time = 0.07s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.25, time = 0.08s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -20.30, time = 0.05s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -20.00, time = 0.10s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -20.11, time = 0.09s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.80, time = 0.10s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.60, time = 0.08s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.60, time = 0.05s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.33, time = 0.06s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.34, time = 0.08s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.31, time = 0.06s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -19.27, time = 0.06s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -19.08, time = 0.06s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -18.66, time = 0.08s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -18.93, time = 0.07s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -18.76, time = 0.07s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -18.33, time = 0.05s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -18.58, time = 0.08s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -18.45, time = 0.06s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -18.24, time = 0.06s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -18.06, time = 0.08s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -18.08, time = 0.06s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -17.77, time = 0.08s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -18.00, time = 0.09s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -18.13, time = 0.07s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -18.04, time = 0.07s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -17.83, time = 0.07s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -17.75, time = 0.08s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -17.79, time = 0.08s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -17.88, time = 0.09s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -17.84, time = 0.07s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -17.63, time = 0.07s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -17.64, time = 0.07s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -17.76, time = 0.07s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -17.93, time = 0.06s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -17.56, time = 0.09s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -17.73, time = 0.06s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -17.71, time = 0.06s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -17.69, time = 0.08s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -17.39, time = 0.06s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -17.52, time = 0.05s\n",
      "[BernoulliRBM] Iteration 51, pseudo-likelihood = -17.37, time = 0.06s\n",
      "[BernoulliRBM] Iteration 52, pseudo-likelihood = -17.50, time = 0.07s\n",
      "[BernoulliRBM] Iteration 53, pseudo-likelihood = -17.59, time = 0.06s\n",
      "[BernoulliRBM] Iteration 54, pseudo-likelihood = -17.35, time = 0.08s\n",
      "[BernoulliRBM] Iteration 55, pseudo-likelihood = -17.28, time = 0.06s\n",
      "[BernoulliRBM] Iteration 56, pseudo-likelihood = -17.19, time = 0.06s\n",
      "[BernoulliRBM] Iteration 57, pseudo-likelihood = -17.37, time = 0.08s\n",
      "[BernoulliRBM] Iteration 58, pseudo-likelihood = -17.58, time = 0.06s\n",
      "[BernoulliRBM] Iteration 59, pseudo-likelihood = -17.13, time = 0.06s\n",
      "[BernoulliRBM] Iteration 60, pseudo-likelihood = -17.35, time = 0.07s\n",
      "[BernoulliRBM] Iteration 61, pseudo-likelihood = -17.22, time = 0.07s\n",
      "[BernoulliRBM] Iteration 62, pseudo-likelihood = -17.25, time = 0.06s\n",
      "[BernoulliRBM] Iteration 63, pseudo-likelihood = -17.33, time = 0.08s\n",
      "[BernoulliRBM] Iteration 64, pseudo-likelihood = -17.08, time = 0.06s\n",
      "[BernoulliRBM] Iteration 65, pseudo-likelihood = -17.20, time = 0.08s\n",
      "[BernoulliRBM] Iteration 66, pseudo-likelihood = -17.32, time = 0.06s\n",
      "[BernoulliRBM] Iteration 67, pseudo-likelihood = -17.17, time = 0.06s\n",
      "[BernoulliRBM] Iteration 68, pseudo-likelihood = -17.14, time = 0.06s\n",
      "[BernoulliRBM] Iteration 69, pseudo-likelihood = -17.01, time = 0.07s\n",
      "[BernoulliRBM] Iteration 70, pseudo-likelihood = -17.09, time = 0.08s\n",
      "[BernoulliRBM] Iteration 71, pseudo-likelihood = -17.09, time = 0.06s\n",
      "[BernoulliRBM] Iteration 72, pseudo-likelihood = -16.99, time = 0.07s\n",
      "[BernoulliRBM] Iteration 73, pseudo-likelihood = -17.06, time = 0.06s\n",
      "[BernoulliRBM] Iteration 74, pseudo-likelihood = -17.02, time = 0.05s\n",
      "[BernoulliRBM] Iteration 75, pseudo-likelihood = -17.05, time = 0.07s\n",
      "[BernoulliRBM] Iteration 76, pseudo-likelihood = -17.08, time = 0.07s\n",
      "[BernoulliRBM] Iteration 77, pseudo-likelihood = -17.01, time = 0.06s\n",
      "[BernoulliRBM] Iteration 78, pseudo-likelihood = -17.05, time = 0.07s\n",
      "[BernoulliRBM] Iteration 79, pseudo-likelihood = -17.03, time = 0.07s\n",
      "[BernoulliRBM] Iteration 80, pseudo-likelihood = -16.92, time = 0.06s\n",
      "[BernoulliRBM] Iteration 81, pseudo-likelihood = -16.94, time = 0.07s\n",
      "[BernoulliRBM] Iteration 82, pseudo-likelihood = -17.17, time = 0.06s\n",
      "[BernoulliRBM] Iteration 83, pseudo-likelihood = -16.89, time = 0.06s\n",
      "[BernoulliRBM] Iteration 84, pseudo-likelihood = -16.97, time = 0.08s\n",
      "[BernoulliRBM] Iteration 85, pseudo-likelihood = -17.06, time = 0.07s\n",
      "[BernoulliRBM] Iteration 86, pseudo-likelihood = -16.88, time = 0.06s\n",
      "[BernoulliRBM] Iteration 87, pseudo-likelihood = -17.14, time = 0.09s\n",
      "[BernoulliRBM] Iteration 88, pseudo-likelihood = -16.80, time = 0.09s\n",
      "[BernoulliRBM] Iteration 89, pseudo-likelihood = -17.00, time = 0.10s\n",
      "[BernoulliRBM] Iteration 90, pseudo-likelihood = -16.95, time = 0.08s\n",
      "[BernoulliRBM] Iteration 91, pseudo-likelihood = -16.89, time = 0.08s\n",
      "[BernoulliRBM] Iteration 92, pseudo-likelihood = -16.92, time = 0.09s\n",
      "[BernoulliRBM] Iteration 93, pseudo-likelihood = -16.91, time = 0.07s\n",
      "[BernoulliRBM] Iteration 94, pseudo-likelihood = -16.76, time = 0.07s\n",
      "[BernoulliRBM] Iteration 95, pseudo-likelihood = -16.99, time = 0.08s\n",
      "[BernoulliRBM] Iteration 96, pseudo-likelihood = -16.89, time = 0.07s\n",
      "[BernoulliRBM] Iteration 97, pseudo-likelihood = -16.88, time = 0.08s\n",
      "[BernoulliRBM] Iteration 98, pseudo-likelihood = -16.97, time = 0.08s\n",
      "[BernoulliRBM] Iteration 99, pseudo-likelihood = -16.74, time = 0.06s\n",
      "[BernoulliRBM] Iteration 100, pseudo-likelihood = -17.06, time = 0.08s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.49, time = 0.07s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -15.59, time = 0.06s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -15.50, time = 0.07s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -15.26, time = 0.08s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -15.22, time = 0.06s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -15.28, time = 0.06s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -15.14, time = 0.08s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -14.90, time = 0.07s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -14.60, time = 0.06s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -14.26, time = 0.08s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -13.67, time = 0.07s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -14.10, time = 0.08s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -13.66, time = 0.07s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -13.40, time = 0.07s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -12.97, time = 0.07s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -13.25, time = 0.08s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -13.04, time = 0.06s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -13.21, time = 0.08s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -13.03, time = 0.08s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -12.97, time = 0.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -12.73, time = 0.07s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -12.68, time = 0.08s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -12.43, time = 0.07s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -12.41, time = 0.06s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -12.48, time = 0.07s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -12.22, time = 0.06s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -12.44, time = 0.06s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -11.99, time = 0.06s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -11.96, time = 0.06s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -12.19, time = 0.05s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -12.61, time = 0.09s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -12.22, time = 0.09s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -12.95, time = 0.10s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -11.84, time = 0.07s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -12.00, time = 0.07s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -12.41, time = 0.07s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -11.74, time = 0.07s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -11.64, time = 0.06s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -11.83, time = 0.06s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -11.54, time = 0.06s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -11.75, time = 0.08s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -11.15, time = 0.07s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -11.61, time = 0.06s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -11.70, time = 0.08s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -11.85, time = 0.07s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -11.66, time = 0.05s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -11.44, time = 0.07s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -11.51, time = 0.06s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -11.67, time = 0.06s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -11.42, time = 0.06s\n",
      "[BernoulliRBM] Iteration 51, pseudo-likelihood = -11.28, time = 0.06s\n",
      "[BernoulliRBM] Iteration 52, pseudo-likelihood = -11.86, time = 0.08s\n",
      "[BernoulliRBM] Iteration 53, pseudo-likelihood = -11.48, time = 0.06s\n",
      "[BernoulliRBM] Iteration 54, pseudo-likelihood = -11.33, time = 0.06s\n",
      "[BernoulliRBM] Iteration 55, pseudo-likelihood = -11.50, time = 0.05s\n",
      "[BernoulliRBM] Iteration 56, pseudo-likelihood = -11.83, time = 0.06s\n",
      "[BernoulliRBM] Iteration 57, pseudo-likelihood = -11.38, time = 0.06s\n",
      "[BernoulliRBM] Iteration 58, pseudo-likelihood = -11.35, time = 0.06s\n",
      "[BernoulliRBM] Iteration 59, pseudo-likelihood = -11.34, time = 0.06s\n",
      "[BernoulliRBM] Iteration 60, pseudo-likelihood = -11.50, time = 0.07s\n",
      "[BernoulliRBM] Iteration 61, pseudo-likelihood = -11.32, time = 0.06s\n",
      "[BernoulliRBM] Iteration 62, pseudo-likelihood = -11.26, time = 0.06s\n",
      "[BernoulliRBM] Iteration 63, pseudo-likelihood = -11.24, time = 0.06s\n",
      "[BernoulliRBM] Iteration 64, pseudo-likelihood = -11.70, time = 0.07s\n",
      "[BernoulliRBM] Iteration 65, pseudo-likelihood = -11.34, time = 0.07s\n",
      "[BernoulliRBM] Iteration 66, pseudo-likelihood = -11.40, time = 0.06s\n",
      "[BernoulliRBM] Iteration 67, pseudo-likelihood = -11.54, time = 0.07s\n",
      "[BernoulliRBM] Iteration 68, pseudo-likelihood = -11.60, time = 0.07s\n",
      "[BernoulliRBM] Iteration 69, pseudo-likelihood = -11.15, time = 0.06s\n",
      "[BernoulliRBM] Iteration 70, pseudo-likelihood = -11.50, time = 0.05s\n",
      "[BernoulliRBM] Iteration 71, pseudo-likelihood = -11.19, time = 0.06s\n",
      "[BernoulliRBM] Iteration 72, pseudo-likelihood = -11.29, time = 0.06s\n",
      "[BernoulliRBM] Iteration 73, pseudo-likelihood = -11.35, time = 0.06s\n",
      "[BernoulliRBM] Iteration 74, pseudo-likelihood = -11.56, time = 0.06s\n",
      "[BernoulliRBM] Iteration 75, pseudo-likelihood = -11.09, time = 0.07s\n",
      "[BernoulliRBM] Iteration 76, pseudo-likelihood = -11.18, time = 0.06s\n",
      "[BernoulliRBM] Iteration 77, pseudo-likelihood = -11.39, time = 0.06s\n",
      "[BernoulliRBM] Iteration 78, pseudo-likelihood = -11.32, time = 0.06s\n",
      "[BernoulliRBM] Iteration 79, pseudo-likelihood = -11.10, time = 0.06s\n",
      "[BernoulliRBM] Iteration 80, pseudo-likelihood = -11.36, time = 0.06s\n",
      "[BernoulliRBM] Iteration 81, pseudo-likelihood = -11.27, time = 0.07s\n",
      "[BernoulliRBM] Iteration 82, pseudo-likelihood = -11.45, time = 0.07s\n",
      "[BernoulliRBM] Iteration 83, pseudo-likelihood = -11.26, time = 0.06s\n",
      "[BernoulliRBM] Iteration 84, pseudo-likelihood = -11.12, time = 0.07s\n",
      "[BernoulliRBM] Iteration 85, pseudo-likelihood = -11.42, time = 0.07s\n",
      "[BernoulliRBM] Iteration 86, pseudo-likelihood = -11.41, time = 0.06s\n",
      "[BernoulliRBM] Iteration 87, pseudo-likelihood = -11.28, time = 0.07s\n",
      "[BernoulliRBM] Iteration 88, pseudo-likelihood = -11.35, time = 0.07s\n",
      "[BernoulliRBM] Iteration 89, pseudo-likelihood = -11.19, time = 0.07s\n",
      "[BernoulliRBM] Iteration 90, pseudo-likelihood = -11.24, time = 0.07s\n",
      "[BernoulliRBM] Iteration 91, pseudo-likelihood = -11.37, time = 0.06s\n",
      "[BernoulliRBM] Iteration 92, pseudo-likelihood = -11.23, time = 0.06s\n",
      "[BernoulliRBM] Iteration 93, pseudo-likelihood = -11.30, time = 0.09s\n",
      "[BernoulliRBM] Iteration 94, pseudo-likelihood = -11.05, time = 0.07s\n",
      "[BernoulliRBM] Iteration 95, pseudo-likelihood = -11.25, time = 0.05s\n",
      "[BernoulliRBM] Iteration 96, pseudo-likelihood = -11.21, time = 0.08s\n",
      "[BernoulliRBM] Iteration 97, pseudo-likelihood = -11.15, time = 0.05s\n",
      "[BernoulliRBM] Iteration 98, pseudo-likelihood = -11.03, time = 0.06s\n",
      "[BernoulliRBM] Iteration 99, pseudo-likelihood = -11.11, time = 0.06s\n",
      "[BernoulliRBM] Iteration 100, pseudo-likelihood = -11.01, time = 0.06s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.99, time = 0.04s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.39, time = 0.06s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -30.10, time = 0.06s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.69, time = 0.06s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.61, time = 0.05s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.71, time = 0.08s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -28.89, time = 0.06s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -28.94, time = 0.06s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -28.50, time = 0.07s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.46, time = 0.05s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.19, time = 0.06s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -27.88, time = 0.07s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -27.87, time = 0.05s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -27.60, time = 0.07s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -27.63, time = 0.06s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -27.56, time = 0.07s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -27.72, time = 0.07s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -27.29, time = 0.05s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -27.40, time = 0.08s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -27.02, time = 0.07s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -27.24, time = 0.06s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -27.05, time = 0.07s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -27.03, time = 0.06s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -26.97, time = 0.06s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -27.16, time = 0.08s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -27.14, time = 0.06s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -26.81, time = 0.06s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -26.79, time = 0.08s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -26.63, time = 0.06s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -26.80, time = 0.07s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -26.71, time = 0.06s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -26.99, time = 0.05s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -26.79, time = 0.05s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -26.79, time = 0.07s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.05, time = 0.06s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -26.90, time = 0.07s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -26.68, time = 0.08s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -26.62, time = 0.07s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -26.62, time = 0.06s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -26.63, time = 0.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -26.60, time = 0.07s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.82, time = 0.06s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.87, time = 0.07s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.72, time = 0.07s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.42, time = 0.07s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.76, time = 0.06s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.69, time = 0.05s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.61, time = 0.06s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.64, time = 0.05s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.68, time = 0.06s\n",
      "[BernoulliRBM] Iteration 51, pseudo-likelihood = -26.84, time = 0.06s\n",
      "[BernoulliRBM] Iteration 52, pseudo-likelihood = -26.35, time = 0.04s\n",
      "[BernoulliRBM] Iteration 53, pseudo-likelihood = -26.31, time = 0.04s\n",
      "[BernoulliRBM] Iteration 54, pseudo-likelihood = -26.34, time = 0.05s\n",
      "[BernoulliRBM] Iteration 55, pseudo-likelihood = -26.47, time = 0.05s\n",
      "[BernoulliRBM] Iteration 56, pseudo-likelihood = -26.36, time = 0.05s\n",
      "[BernoulliRBM] Iteration 57, pseudo-likelihood = -26.40, time = 0.05s\n",
      "[BernoulliRBM] Iteration 58, pseudo-likelihood = -26.47, time = 0.06s\n",
      "[BernoulliRBM] Iteration 59, pseudo-likelihood = -26.31, time = 0.04s\n",
      "[BernoulliRBM] Iteration 60, pseudo-likelihood = -26.46, time = 0.05s\n",
      "[BernoulliRBM] Iteration 61, pseudo-likelihood = -26.56, time = 0.04s\n",
      "[BernoulliRBM] Iteration 62, pseudo-likelihood = -26.33, time = 0.06s\n",
      "[BernoulliRBM] Iteration 63, pseudo-likelihood = -26.40, time = 0.06s\n",
      "[BernoulliRBM] Iteration 64, pseudo-likelihood = -26.40, time = 0.05s\n",
      "[BernoulliRBM] Iteration 65, pseudo-likelihood = -26.54, time = 0.06s\n",
      "[BernoulliRBM] Iteration 66, pseudo-likelihood = -26.43, time = 0.05s\n",
      "[BernoulliRBM] Iteration 67, pseudo-likelihood = -26.39, time = 0.06s\n",
      "[BernoulliRBM] Iteration 68, pseudo-likelihood = -26.26, time = 0.05s\n",
      "[BernoulliRBM] Iteration 69, pseudo-likelihood = -26.26, time = 0.04s\n",
      "[BernoulliRBM] Iteration 70, pseudo-likelihood = -26.22, time = 0.05s\n",
      "[BernoulliRBM] Iteration 71, pseudo-likelihood = -26.14, time = 0.05s\n",
      "[BernoulliRBM] Iteration 72, pseudo-likelihood = -26.11, time = 0.05s\n",
      "[BernoulliRBM] Iteration 73, pseudo-likelihood = -26.15, time = 0.04s\n",
      "[BernoulliRBM] Iteration 74, pseudo-likelihood = -26.27, time = 0.04s\n",
      "[BernoulliRBM] Iteration 75, pseudo-likelihood = -26.03, time = 0.05s\n",
      "[BernoulliRBM] Iteration 76, pseudo-likelihood = -26.48, time = 0.06s\n",
      "[BernoulliRBM] Iteration 77, pseudo-likelihood = -26.05, time = 0.05s\n",
      "[BernoulliRBM] Iteration 78, pseudo-likelihood = -26.18, time = 0.04s\n",
      "[BernoulliRBM] Iteration 79, pseudo-likelihood = -26.25, time = 0.05s\n",
      "[BernoulliRBM] Iteration 80, pseudo-likelihood = -25.99, time = 0.04s\n",
      "[BernoulliRBM] Iteration 81, pseudo-likelihood = -26.19, time = 0.05s\n",
      "[BernoulliRBM] Iteration 82, pseudo-likelihood = -26.07, time = 0.05s\n",
      "[BernoulliRBM] Iteration 83, pseudo-likelihood = -26.07, time = 0.05s\n",
      "[BernoulliRBM] Iteration 84, pseudo-likelihood = -25.95, time = 0.06s\n",
      "[BernoulliRBM] Iteration 85, pseudo-likelihood = -25.66, time = 0.04s\n",
      "[BernoulliRBM] Iteration 86, pseudo-likelihood = -25.90, time = 0.04s\n",
      "[BernoulliRBM] Iteration 87, pseudo-likelihood = -26.02, time = 0.04s\n",
      "[BernoulliRBM] Iteration 88, pseudo-likelihood = -25.99, time = 0.04s\n",
      "[BernoulliRBM] Iteration 89, pseudo-likelihood = -26.09, time = 0.06s\n",
      "[BernoulliRBM] Iteration 90, pseudo-likelihood = -26.18, time = 0.05s\n",
      "[BernoulliRBM] Iteration 91, pseudo-likelihood = -25.86, time = 0.05s\n",
      "[BernoulliRBM] Iteration 92, pseudo-likelihood = -26.07, time = 0.05s\n",
      "[BernoulliRBM] Iteration 93, pseudo-likelihood = -25.78, time = 0.06s\n",
      "[BernoulliRBM] Iteration 94, pseudo-likelihood = -25.98, time = 0.06s\n",
      "[BernoulliRBM] Iteration 95, pseudo-likelihood = -25.82, time = 0.04s\n",
      "[BernoulliRBM] Iteration 96, pseudo-likelihood = -25.98, time = 0.04s\n",
      "[BernoulliRBM] Iteration 97, pseudo-likelihood = -25.97, time = 0.06s\n",
      "[BernoulliRBM] Iteration 98, pseudo-likelihood = -25.85, time = 0.04s\n",
      "[BernoulliRBM] Iteration 99, pseudo-likelihood = -25.96, time = 0.05s\n",
      "[BernoulliRBM] Iteration 100, pseudo-likelihood = -25.90, time = 0.04s\n",
      "Logistic regression using RBM features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       0.89      0.94      0.92        35\n",
      "           2       1.00      0.83      0.91        36\n",
      "           3       0.58      0.86      0.69        29\n",
      "           4       1.00      0.93      0.97        30\n",
      "           5       0.95      0.90      0.92        40\n",
      "           6       1.00      0.98      0.99        44\n",
      "           7       0.93      0.97      0.95        39\n",
      "           8       0.86      0.82      0.84        39\n",
      "           9       0.78      0.68      0.73        41\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUSHANT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = np.asarray(digits.data, 'float32')\n",
    "Y = digits.target\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(C=100)\n",
    "rbm1 = BernoulliRBM(n_components=100, learning_rate=0.06, n_iter=100, verbose=1, random_state=101)\n",
    "rbm2 = BernoulliRBM(n_components=80, learning_rate=0.06, n_iter=100, verbose=1, random_state=101)\n",
    "rbm3 = BernoulliRBM(n_components=60, learning_rate=0.06, n_iter=100, verbose=1, random_state=101)\n",
    "DBN3 = Pipeline(steps=[('rbm1', rbm1),('rbm2', rbm2), ('rbm3', rbm3), ('logistic', logistic)])\n",
    "\n",
    "DBN3.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        DBN3.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
